# Nano-GPT-from-scratch-novels
My implementation of Andrej Karpathy's 'Let's build GPT', adapted for Chinese datasets. Includes a complete workflow from raw text cleaning (encoding fix) to Bigram baselines and final Transformer training.

#  Nano language models project (Project Sandworm)

A lightweight Transformer model trained on the Chinese translation of Frank Herbert's *Dune*.

##  What is this?
This project reproduces the GPT architecture (based on [nanoGPT](https://github.com/karpathy/nanoGPT)) to learn and generate text in the style of the Chinese Sci-Fi novel *Dune*.

##  Key Features
* **Full Pipeline:** From raw `.txt` processing to model training.
* **Chinese Support:** Includes a custom script to handle GBK/GB18030 encoding issues common in Chinese datasets.
* **One-Click Run:** Designed to run entirely on Google Colab's free tier (T4 GPU).

##  How to Use
1. Open the notebook in Google Colab.
2. Upload your `input.txt` (Any novel you'd like).
3. Run all cells to handle encoding and start training.

##  Results
å· 18
â€œæˆ‘åšäº†ä»€ä¹ˆäº‹ï¼Œæˆ‘è§‰å¾—ä½ ä¸€å®šè¦ç»§ç»­è®­ç»ƒâ€¦â€¦â€
â€œæ˜¯ä¸ºäº†ç®—çš„ã€‚â€
â€œæˆ‘ä¹Ÿè®¸è®©ä½ å„¿å­æ‹¥æœ‰è¿™äº‹åŠ¡ã€‚â€
æ°è¥¿å¡æ„Ÿåˆ°å¿ƒç©ºæ°”çš„ä¸€ä¸ååº”ã€‚è¿™æ˜¯ç”±ï¼Œé‚£å£°éŸ³ä½¿å¥¹å´é€éœ²å‡ºäº†æ¾çš„å¿ƒçœ¼ã€‚â€œæˆ‘ä¹ŸçŸ¥é“å…¬çˆµçš„å¼ºå¿æœ‰äº†ä¸€åˆ‡ï¼Œä½†æˆ‘è¿˜è¦è€ƒè™‘ã€‚â€
â€œä¹Ÿä¼šå–œæ¬¢è¿™æ˜¯ä¸ªæ˜Ÿçƒã€‚â€å“ˆç“¦ç‰¹è¯´ã€‚
â€œè€Œä¸æ˜¯é•‡å®šå§ï¼Œå¤§äººï¼Œâ€ä»–è¯´ï¼Œâ€œä»–æ˜¯ä¸€ä¸ªå„å´”è¿ªäººã€‚å¼—é›·æ›¼äººåœ¨å¸®ä»–ä»¬å—ï¼Ÿâ€
â€œä»–å…ˆä¹Ÿè®¸ã€‚â€
â€œçŸ¥é“ä»–ä»¬æ˜¯å¼—é›·æ›¼äººçš„æœ‹å‹ï¼Œè‰¾è¾¾è·ä¸ºå¤å§†é²æ–¯&#183;å¡åº·è¾¾æ–¯ï¼Œè„¸ä¸Šè°ˆä»¶ä»–çš„äº‹ã€‚â€å“ˆç“¦ç‰¹è¯´ï¼Œä»–çš„è¯ä¾¿è½¬å›åˆ°ä¸€ä¸‹ï¼Œéœ²å‡ºäº†çª—æˆ·ï¼Œâ€œå¦‚æœè¢«ä¿˜çš„å¯èƒ½å¤ªå¤šï¼Œæˆ‘ä»¬å¾—ç™½æµªè´¹åå¯¹çš„ï¼â€
â€œæˆ‘è¯¥è¯´ï¼Œå…¬çˆµï¼Ÿâ€å“ˆç“¦ç‰¹ç«™ç›´æ¥åœ°é—®ã€‚
ä¿ç½—èº«ä½“çš„è¿™ä½çœŸæ˜¯æ¼«é•¿é•¿çš„é’»æ€å­¦å®¶æ‰­æ›²äº†å›å»ã€‚å±‹å­ï¼Œä¿ç½—çº³äº†ä¸€ä»¶äº‹ï¼Œæ»¡é¢çš„å¦‚æœä»–çš„å®¶é¢„çŸ¥èƒ½æ€§ã€‚
â€œä½ æ€ä¹ˆè¯´è¿‡æ»¤å™¨ï¼Œâ€å…¬çˆµè¯´ï¼Œâ€œå¥½å¥½å§ï¼Œå°å¿ƒæƒ…å†µä¼¤å¿ƒå¤§çš„åŒ»ç”Ÿï¼Œå®ƒèƒ½ç¡®å‘ç”Ÿæ²‰ç¡äº†ï¼Œæˆ–æ˜¯é€ƒé¿ã€‚â€å“ˆè±å…‹è¯´ã€‚ä»–çªç„¶é¡¿äº†ä¸€ä¸‹ç´ï¼Œâ€œå“¥å°¼ã€‚â€ä»–åˆæ‰«äº†ä¸€çœ¼å±‹é—¨ï¼Œâ€œå“¥å°¼ã€‚â€
å“ˆè±å…‹å¤§æ­¥èµ°äº†è¿›æ¥ã€‚ä»–è½¬å‘å±‹å­æ—¶ï¼Œé•¿è¢çš„æ¡Œå­ã€‚ä»–è½¬è¿‡èº«ï¼Œä¼¸è¿›å…¥ä¸€æ­¥æ¶Œå…¥çš„æ‰‹ä»¶å¤–è¡£ç ´å£ï¼Œåœ¨å±è”½åœºå†…é¢ï¼Œæ­£åšå¥½ç¿»ã€‚
â€œæˆ‘å–œçˆ±ä¸€å‘œå•Šã€‚â€ä¿ç½—è¯´ã€‚
ä¿ç½—æƒ³ï¼šä¸ºä»€ä¹ˆä¸æƒ³è¯´ä»–æƒ³çš„é‚£äº›æ‰‹éšä»–å»ç‰›å¤´ï¼ŒçœŸæ˜¯å¯¹

*Model reaching a train loss of 0.13 but value loss of 9.0 after 5000 steps.*

## ğŸ™Œ Credits
Based on the educational materials by Andrej Karpathy.
